# -*- coding: utf-8 -*-
"""Untitled4.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10g2CSyvQkoMzt2ScJXDVz5T7a444k2P2
"""

pip install datasets

from datasets import load_dataset

# 1. Load the ADE Corpus V2 for the Classification Task
# This task has 'text' (the sentence) and 'label' (0: Not ADE, 1: ADE)
classification_dataset = load_dataset("SetFit/ade_corpus_v2_classification")

print("--- ADE Classification Dataset Structure ---")
print(classification_dataset)

# You can access the training split like this:
train_data = classification_dataset['train']
print("\nFirst row of Training Data:")
print(train_data[0])

# 2. Load the ADE Corpus V2 for the Relation Extraction Task (Drug-AE relations)
# This task is more complex, typically containing drug/ADE entity positions and relation type.
# Use the core dataset name for the relation task.
relation_dataset = load_dataset("ade_corpus_v2", "Ade_corpus_v2_drug_ade_relation")

print("\n--- ADE Relation Extraction Dataset Structure ---")
print(relation_dataset)

import pandas as pd
from datasets import load_dataset

# Load the classification dataset (example)
dataset = load_dataset("SetFit/ade_corpus_v2_classification")
df = pd.DataFrame(dataset['train'])

# Drop duplicates based on the 'text' column
initial_rows = len(df)
df.drop_duplicates(subset=['text'], inplace=True)
final_rows = len(df)

print(f"Removed {initial_rows - final_rows} duplicates.")

# Filter out texts with less than 3 words
df['word_count'] = df['text'].apply(lambda x: len(x.split()))
df = df[df['word_count'] >= 3]

pip install datasets transformers pandas

from datasets import load_dataset
import pandas as pd

# Load the Relation Extraction subset of the ADE Corpus V2
# This dataset contains the entity spans and relation links.
print("Loading ADE Corpus V2 (Relation Extraction subset)...")
relation_dataset = load_dataset("ade_corpus_v2", "Ade_corpus_v2_drug_ade_relation")

def extract_relation_data(example):
    """Extracts entities and structures them into relation triples and an entities_map from the 'Ade_corpus_v2_drug_ade_relation' dataset."""
    text = example['text']
    drug_text = example['drug']
    effect_text = example['effect']
    raw_indexes = example['indexes'] # This is a dictionary like {'drug': {...}, 'effect': {...}}

    relation_triples = []
    entities_map = {}
    unique_entity_id = 0

    # Extract drug entity and its span
    drug_span_info = raw_indexes.get('drug')
    if drug_span_info and drug_span_info.get('start_char') and drug_span_info.get('end_char'):
        drug_start = drug_span_info['start_char'][0]
        drug_end = drug_span_info['end_char'][0]
        entities_map[str(unique_entity_id)] = {
            'text': drug_text,
            'start': drug_start,
            'end': drug_end,
            'type': 'Drug'
        }
        head_entity_key = str(unique_entity_id)
        unique_entity_id += 1
    else:
        # Skip example if drug span is malformed or missing
        return {'relation_triples': [], 'original_text': text, 'entities_map': {}}

    # Extract effect entity and its span
    effect_span_info = raw_indexes.get('effect')
    if effect_span_info and effect_span_info.get('start_char') and effect_span_info.get('end_char'):
        effect_start = effect_span_info['start_char'][0]
        effect_end = effect_span_info['end_char'][0]
        entities_map[str(unique_entity_id)] = {
            'text': effect_text,
            'start': effect_start,
            'end': effect_end,
            'type': 'Adverse_Event'
        }
        tail_entity_key = str(unique_entity_id)
        unique_entity_id += 1
    else:
        # Skip example if effect span is malformed or missing
        return {'relation_triples': [], 'original_text': text, 'entities_map': {}}

    # Now construct the relation triple using the extracted spans
    relation_type = 'Causes' # As determined previously

    triple = {
        'text': text,
        'head_entity_text': drug_text,
        'tail_entity_text': effect_text,
        'relation_label': relation_type,
        'head_span': (drug_start, drug_end),
        'tail_span': (effect_start, effect_end)
    }
    relation_triples.append(triple)

    return {'relation_triples': relation_triples, 'original_text': text, 'entities_map': entities_map}

# Apply the mapping function to the dataset splits
processed_dataset = relation_dataset.map(extract_relation_data, batched=False)

print("\nSample Relation Triple:")
# Filter for examples that actually have relation triples
filtered_processed_train = processed_dataset['train'].filter(lambda x: len(x['relation_triples']) > 0)

if len(filtered_processed_train) > 0:
    # Get the first example from the filtered dataset
    first_example_with_triple = filtered_processed_train[0]
    # Now explode its relation_triples to get the first actual triple
    sample_df = pd.DataFrame([first_example_with_triple]).explode('relation_triples').dropna()
    print(sample_df['relation_triples'].iloc[0])
else:
    print("No valid relation triples were generated for any example in the training set.")

from transformers import AutoTokenizer

# The BioBERT tokenizer
MODEL_NAME = "dmis-lab/biobert-base-cased-v1.1"
tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)

# Define the NER label list and map it to IDs
label_list = ['O', 'B-DRUG', 'I-DRUG', 'B-AE', 'I-AE']
label_to_id = {label: i for i, label in enumerate(label_list)}

def tokenize_and_align_labels(example):
    """Tokenizes text and aligns entity spans to create IOB tags (numerical labels)."""

    tokenized_input = tokenizer(example['original_text'], truncation=True, is_split_into_words=False)

    tokens = tokenized_input.tokens()
    if tokens is None or len(tokens) == 0:
        # Handle cases where tokenization yields no tokens or tokens is None
        return {**tokenized_input, 'labels': [], 'relation_triples': example['relation_triples']}

    # Initialize token labels with 'O' (Outside)
    labels = ['O'] * len(tokens)

    # Map entity data from the 'entities_map' created in Step 2
    entities_map = example['entities_map']

    if not isinstance(entities_map, dict):
        print(f"Warning: entities_map is not a dict: {entities_map} for example: {example.get('original_text', 'N/A')}")
        return {**tokenized_input, 'labels': labels, 'relation_triples': example['relation_triples']}

    for ent_id, ent_data in entities_map.items():
        if ent_data is None:
            print(f"Warning: ent_data is None for ent_id {ent_id} in example: {example.get('original_text', 'N/A')}")
            continue # Skip this malformed entry

        ent_type = ent_data['type']
        char_start, char_end = ent_data['start'], ent_data['end']

        # Determine the IOB tag prefix
        if ent_type == 'Drug':
            iob_prefix = 'DRUG'
        elif ent_type == 'Adverse_Event':
            iob_prefix = 'AE'
        else:
            continue

        # Use the tokenizer's offset mapping to find the token indices for the character span
        token_indices = tokenized_input.char_to_token(char_start)

        if token_indices is None:
             # Skip entities that fall completely outside the tokenizer's range/max length
             continue

        # Find all tokens belonging to this entity
        current_token_idx = token_indices

        # Start with B- tag
        if current_token_idx < len(labels):
            labels[current_token_idx] = f"B-{iob_prefix}"

        # Look ahead for I- tags until the end of the entity span is passed
        while current_token_idx + 1 < len(tokens):
            next_token_idx = current_token_idx + 1
            token_span = tokenized_input.token_to_chars(next_token_idx)

            if token_span is None or token_span.start >= char_end:
                break

            # If the next token is inside the entity span, tag it as I-
            if next_token_idx < len(labels):
                labels[next_token_idx] = f"I-{iob_prefix}"
            current_token_idx = next_token_idx

    # Convert IOB string labels to numerical IDs
    tokenized_input['labels'] = [label_to_id[label] for label in labels]

    # Pass along the relation triples for the RE component
    tokenized_input['relation_triples'] = example['relation_triples']

    return tokenized_input

# Apply the tokenization and labeling across the entire dataset
# Now that extract_relation_data provides 'entities_map', we can remove the original columns.
final_processed_dataset = processed_dataset.map(
    tokenize_and_align_labels,
    batched=False,
    remove_columns=['original_text', 'entities_map'], # Remove intermediate columns after use
    load_from_cache_file=False # Force recomputation to avoid potential caching issues
)

print("\n--- Sample Tokenized Output (First Row) ---")
# Display the tokens and their numerical labels
sample_tokens = tokenizer.convert_ids_to_tokens(final_processed_dataset['train'][0]['input_ids'])
sample_labels = final_processed_dataset['train'][0]['labels']
print(pd.DataFrame({'Token': sample_tokens, 'Label_ID': sample_labels, 'Label_Name': [label_list[i] for i in sample_labels]}).head(10).to_markdown(index=False))

!pip install datasets transformers pandas evaluate seqeval



import torch
from transformers import AutoModelForTokenClassification, TrainingArguments, Trainer
from evaluate import load
import numpy as np

MODEL_NAME = "dmis-lab/biobert-base-cased-v1.1"
# Define the NER label list and map it to IDs
label_list = ['O', 'B-DRUG', 'I-DRUG', 'B-AE', 'I-AE']
num_labels = len(label_list)

# Load the metric
metric = load("seqeval")

print("Loading BioBERT model for Token Classification...")
model = AutoModelForTokenClassification.from_pretrained(
    MODEL_NAME,
    num_labels=num_labels,
    # Configure ID to Label mapping for better logging/saving
    id2label={i: label for i, label in enumerate(label_list)},
    label2id={label: i for i, label in enumerate(label_list)}
)

metric = load("seqeval")

def compute_metrics(p):
    """Computes sequence evaluation metrics (F1) for NER."""
    predictions, labels = p
    # Get the predicted label index (highest score)
    predictions = np.argmax(predictions, axis=2)

    # Convert ID labels back to string labels for metric computation
    true_predictions = [
        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]
        for prediction, label in zip(predictions, labels)
    ]
    true_labels = [
        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]
        for prediction, label in zip(predictions, labels)
    ]

    results = metric.compute(predictions=true_predictions, references=true_labels)

    # Return micro-averaged F1 and overall accuracy
    return {
        "precision": results["overall_precision"],
        "recall": results["overall_recall"],
        "f1": results["overall_f1"],
        "accuracy": results["overall_accuracy"],
    }

from transformers import Trainer, TrainingArguments

# ... (define model, tokenizer, datasets, label_list)

training_args = TrainingArguments(
    # Your other arguments...
    output_dir="./ner_results",
    eval_strategy="epoch",  # Corrected argument name
    save_strategy="epoch", # Added to match eval_strategy for load_best_model_at_end
    load_best_model_at_end=True,
    label_names=["labels"], # Explicitly tell Trainer which column is the label
    remove_unused_columns=True, # Crucial: remove columns not used by the model (like relation_triples)
)

trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=final_processed_dataset["train"],
    eval_dataset=final_processed_dataset["train"], # Using 'train' split for evaluation here, you might want to use a separate 'validation' split if available
    tokenizer=tokenizer,
    # ðŸŒŸ CRITICAL LINE: Pass the function here! ðŸŒŸ
    compute_metrics=compute_metrics,
)

import numpy as np
from evaluate import load # Corrected import from datasets import load_metric
from transformers import AutoModelForTokenClassification, AutoTokenizer, Trainer, TrainingArguments

# â”¬Ëœ Define your label list (Example for CoNLL-2003 NER)
label_list = ['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC']

# â”¬Ëœ Load the metric
metric = load("seqeval")

def compute_metrics(p):
    """Computes sequence evaluation metrics (F1) for NER."""
    predictions, labels = p
    # Get the predicted label index (highest score)
    predictions = np.argmax(predictions, axis=2)

    # Convert ID labels back to string labels for metric computation
    true_predictions = [
        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]
        for prediction, label in zip(predictions, labels)
    ]
    true_labels = [
        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]
        for prediction, label in zip(predictions, labels)
    ]

    results = metric.compute(predictions=true_predictions, references=true_labels)

    # Return overall metrics in the dictionary format expected by the Trainer
    return {
        "precision": results["overall_precision"],
        "recall": results["overall_recall"],
        "f1": results["overall_f1"],
        "accuracy": results["overall_accuracy"]
    }

# â”¬Ëœ Load Model and Tokenizer (Example using a pre-trained model)
model_name = "bert-base-uncased" # Or any other suitable model
model = AutoModelForTokenClassification.from_pretrained(
    model_name,
    num_labels=len(label_list)
)
tokenizer = AutoTokenizer.from_pretrained(model_name)
# ... (Assume tokenized_datasets is loaded and ready)

# â”¬Ëœ Define Training Arguments
training_args = TrainingArguments(
    output_dir="./ner_results",
    num_train_epochs=3,
    per_device_train_batch_size=16,
    per_device_eval_batch_size=16,
    warmup_steps=500,
    weight_decay=0.01,
    logging_dir='./logs',
    logging_steps=500,

    # ðŸ‘‡ CRITICAL FOR METRICS: Evaluate after every epoch/step
    eval_strategy="epoch",
    save_strategy="epoch",  # Corrected to match eval_strategy
    load_best_model_at_end=True, # Optional, but good practice
    metric_for_best_model="f1"  # Specify which metric to monitor
)

from transformers import DataCollatorForTokenClassification

# Initialize the DataCollator for Token Classification
data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)

# ðŸ“Œ Initialize the Trainer
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=final_processed_dataset["train"],
    eval_dataset=final_processed_dataset["train"], # Using the train set for evaluation as final_processed_dataset only has a train split
    tokenizer=tokenizer,
    data_collator=data_collator, # Explicitly provide the data collator

    # ðŸ‘‡ THIS IS THE CONNECTION POINT
    compute_metrics=compute_metrics,
)

# ðŸ“Œ Start Training
print("Starting training...")
trainer.train()

# ðŸ“Œ Final Evaluation (Optional, but recommended)
print("\nFinal evaluation on test set:")
# Replace "validation" with "test" if you have a separate test set
results = trainer.evaluate(final_processed_dataset["train"]) # Using the train set for evaluation
print(results)

print("\n--- Inspecting raw relation_dataset examples ---")
for i in range(5):
    print(f"\nExample {i}:")
    example = relation_dataset['train'][i]
    print(f"  Text: {example['text']}")
    print(f"  Drug: {example['drug']}")
    print(f"  Effect: {example['effect']}")
    print(f"  Indexes: {example['indexes']}")